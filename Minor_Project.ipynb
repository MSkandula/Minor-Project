{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2nLNP1bE0kb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization,Dropout,InputLayer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from seaborn import heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLLPOREmGr77"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PBk5xPiGD3U"
      },
      "outputs": [],
      "source": [
        "def RA_DA():\n",
        "  raw_data=tfds.as_numpy(tfds.load('colorectal_histology',split=['train'],batch_size=-1,shuffle_files = True,as_supervised=True,))\n",
        "\n",
        "  img = raw_data[0][0]\n",
        "  label = raw_data[0][1]\n",
        "\n",
        "  return img ,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ7f3tfGGF-j"
      },
      "outputs": [],
      "source": [
        "img, label = RA_DA()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcGxnT9OMpgx"
      },
      "outputs": [],
      "source": [
        "print('''Raw Data\n",
        "Images: {0}\n",
        "Each image size is: {1} '''.format(img.shape[0],img.shape[1::]))\n",
        "#0-no of images\n",
        "#1::-dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr0Hz6HrNN1N"
      },
      "outputs": [],
      "source": [
        "tissue_types = {0 : \"Tumor\" ,1 : \"Debris\" ,2 : \"Stroma\" ,3 : \"Lympho\" , 4 : \"complex\" , 5 : \"Mucosa\" ,6 : \"Adipose\"  ,7 : \"Empty\",  }\n",
        "tissue_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3qwzC5tNfwU"
      },
      "outputs": [],
      "source": [
        "for j in range(0,8,1):\n",
        "    [idx] = np.where(label==j)\n",
        "    plt.figure(figsize=(10,5))\n",
        "    for i in range(10):\n",
        "        plt.subplot(1,10,i+1)\n",
        "        plt.imshow(img[idx[i]])\n",
        "        plt.xticks([]), plt.yticks([])\n",
        "        plt.title(tissue_types.get(label[idx[i]]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_to_train_and_test(X, y, test_ratio, rand_state = None):\n",
        "    return train_test_split(X, y, test_size = test_ratio, random_state = rand_state)\n",
        "\n",
        "def get_train_and_test_generator(train_images, train_labels, test_images, test_labels):\n",
        "\n",
        "\n",
        "    data_gen_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "\n",
        "\n",
        "    train_generator = data_gen_train.flow(x = train_images,y=train_labels,batch_size=32,shuffle=True)\n",
        "    test_generator = data_gen_train.flow(x = test_images,y=test_labels,batch_size=32,shuffle=True)\n",
        "\n",
        "    return train_generator, test_generator"
      ],
      "metadata": {
        "id": "EOBr_Lc4FJn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98aoENFHN_CJ"
      },
      "outputs": [],
      "source": [
        "train_images,test_images, train_labels, test_labels = split_to_train_and_test(img, label, 0.2)\n",
        "print(train_images.shape,test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values, counts = np.unique(test_labels, return_counts=True)\n",
        "values"
      ],
      "metadata": {
        "id": "DkcErpfeE7Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts"
      ],
      "metadata": {
        "id": "E-cMO2CSHrlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_generator_images(train_generator, all_label_dictionary):\n",
        "\n",
        "  x_batch, y_batch = train_generator.next()\n",
        "\n",
        "  plt.figure(figsize=(15,8))\n",
        "  for i,x in enumerate(x_batch):\n",
        "      plt.subplot(4,8,i+1)\n",
        "      plt.imshow(x)\n",
        "      plt.title(all_label_dictionary.get(y_batch[i]))\n",
        "      plt.axis('off')\n",
        "\n",
        "  print('x_batch.shape = ',x_batch.shape)\n",
        "  print('y_batch.shape = ',y_batch.shape)"
      ],
      "metadata": {
        "id": "4dC40-f0HsXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator, test_generator = get_train_and_test_generator(train_images, train_labels, test_images, test_labels)"
      ],
      "metadata": {
        "id": "O5EJaxP_HysN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[0]"
      ],
      "metadata": {
        "id": "iZsenVB3Og-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_generator_images(train_generator, tissue_types)"
      ],
      "metadata": {
        "id": "NXAXjrWYH_WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_generator_images(test_generator, tissue_types)"
      ],
      "metadata": {
        "id": "-fJUBpqiIoYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sample(X, y, index):\n",
        "    plt.figure(figsize = (15,2))\n",
        "    plt.imshow(X[index])\n",
        "    plt.xlabel(tissue_types[y[index]])"
      ],
      "metadata": {
        "id": "VJz7tXqF6rxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sample(train_images, train_labels, 5)"
      ],
      "metadata": {
        "id": "pV5BCUh_6wIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "PIc9Hl2FI6q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Sequential()\n",
        "\n",
        "model_1.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding='same', input_shape=(150, 150,3)))\n",
        "model_1.add(BatchNormalization())\n",
        "model_1.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(BatchNormalization())\n",
        "\n",
        "model_1.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
        "model_1.add(BatchNormalization())\n",
        "model_1.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(BatchNormalization())\n",
        "\n",
        "model_1.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(BatchNormalization())\n",
        "model_1.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(BatchNormalization())\n",
        "model_1.add(Dropout(0.2))\n",
        "\n",
        "model_1.add(Conv2D(256, kernel_size=(3, 3), activation=\"relu\", padding='same'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(BatchNormalization())\n",
        "model_1.add(Dropout(0.2))\n",
        "\n",
        "model_1.add(Flatten())\n",
        "\n",
        "model_1.add(Dense(128, activation='relu'))\n",
        "model_1.add(Dropout(0.2))\n",
        "\n",
        "model_1.add(Dense(1000, activation='relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "\n",
        "model_1.add(Dense(8, activation='softmax'))\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "IID5qZmkI_1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4000//32"
      ],
      "metadata": {
        "id": "WI7gLalGjYDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Adam = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.8, beta_2=0.999, epsilon=1e-07)\n",
        "\n",
        "model_1.compile(optimizer=Adam,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Y4E-a_FBj_qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(train_generator, steps_per_epoch=125, epochs=12,\n",
        "                    validation_data=(test_generator))"
      ],
      "metadata": {
        "id": "odewNAa7kBv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history_after_training(i_History):\n",
        "\n",
        "    plt.figure(figsize=(14,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(i_History.history['loss'],':or',label = \"Train Data\")\n",
        "    plt.plot(i_History.history['val_loss'],'-og',label = \"Test Data\")\n",
        "    plt.title('Loss',fontsize=14)\n",
        "    plt.xlabel('Epochs',fontsize=14)\n",
        "    plt.legend(loc = \"upper left\")\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(i_History.history['accuracy'],':ob',label = \"Train Data\")\n",
        "    plt.plot(i_History.history['val_accuracy'],'-oc',label = \"Test Data\")\n",
        "    plt.ylim([0, 1])\n",
        "    plt.title('Accuracy',fontsize=12)\n",
        "    plt.xlabel('Epochs',fontsize=12)\n",
        "    plt.legend(loc = \"upper left\")\n",
        "    plt.grid()"
      ],
      "metadata": {
        "id": "J2WOlyJmneTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history_after_training(history_1)"
      ],
      "metadata": {
        "id": "0KneKzQTkDuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Adam = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.6, beta_2=0.999, epsilon=1e-07)\n",
        "\n",
        "model_1.compile(optimizer=Adam,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history_1_1 = model_1.fit(train_generator, steps_per_epoch=125, epochs=20,\n",
        "                    validation_data=(test_generator))"
      ],
      "metadata": {
        "id": "A6462-VvkFtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history_after_training(history_1_1)"
      ],
      "metadata": {
        "id": "zaT0Dr3ikHqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.save('model_1.h5')"
      ],
      "metadata": {
        "id": "XyEIT5AGkJPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(model, class_names, test_img, test_labels, model_name):\n",
        "  yhat_1_hot = model.predict(test_img)\n",
        "  yhat = np.argmax(yhat_1_hot, axis=1)\n",
        "  matrix = confusion_matrix(test_labels, yhat)\n",
        "  confusion_normalized_matrix = matrix / matrix.sum(axis=1)\n",
        "\n",
        "  plt.figure(figsize=(10,8))\n",
        "  heatmap(confusion_normalized_matrix,xticklabels=class_names, yticklabels=class_names,cmap='Blues',annot=True, fmt='.2%')\n",
        "  plt.xlabel('Predicted label', fontsize=18)\n",
        "  plt.ylabel('True label', fontsize=18)\n",
        "  plt.title(str(model_name),fontsize=20)\n",
        "  plt.show()\n",
        "\n",
        "def get_accuracy_and_loss(model, test_images, test_labels):\n",
        "  return model.evaluate(test_images, test_labels, verbose=0)"
      ],
      "metadata": {
        "id": "jUUkch6umldn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy_and_loss(model_1,test_images,test_labels)"
      ],
      "metadata": {
        "id": "R66k96f0yVPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(model_1,tissue_types.values(),test_images,test_labels,'Model 1')"
      ],
      "metadata": {
        "id": "uqCmfodQl8h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "label_pred=model_1.predict(test_images)\n",
        "label_pred_classes=[np.argmax(element) for element in label_pred]\n",
        "print(\"Classification Report:\\n\",classification_report(test_labels,label_pred_classes))"
      ],
      "metadata": {
        "id": "oZ2SXvtPBUa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_images)\n"
      ],
      "metadata": {
        "id": "wUFMl9DFulhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images[999]"
      ],
      "metadata": {
        "id": "PmdsCd98pGA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sample(train_images, test_labels, 500)"
      ],
      "metadata": {
        "id": "choRj0e95_3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = get_accuracy_and_loss(model_1, test_images, test_labels)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "id": "IhqLQ5eLrmlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tissue_types[test_labels[0]]"
      ],
      "metadata": {
        "id": "bbdkb8gUMKqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_pred= model_1.predict(test_images).round(2)\n",
        "label_pred"
      ],
      "metadata": {
        "id": "9yXW-fMszjmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualize Output\n"
      ],
      "metadata": {
        "id": "cqRpWV9wzimy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,30))\n",
        "j=1\n",
        "for i in np.random.randint(0,1000,60):\n",
        "  plt.subplot(10,6,j);j+=1\n",
        "  plt.imshow(test_images[i],cmap='Greys')\n",
        "  plt.title('Actual = {} / {} \\nPredicted = {} / {}'.format(tissue_types[test_labels[i]],test_labels[i],tissue_types[np.argmax(label_pred[i])],np.argmax(label_pred[i])))\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "CKaHJ2Ilzsj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 2 using Transfer learning\n"
      ],
      "metadata": {
        "id": "hhd9REgqBeZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = keras.Sequential()\n",
        "\n",
        "vgg16 = tf.keras.applications.VGG16(input_shape=(150,150,3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "vgg16.summary()"
      ],
      "metadata": {
        "id": "jd8LSPedtydw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('#layer \\t layer-name \\t trainable')\n",
        "print('------ \\t ---------- \\t ---------')\n",
        "\n",
        "for (i,layer) in enumerate(vgg16.layers):\n",
        "    print(str(i),'\\t', layer.__class__.__name__, '\\t',layer.trainable)\n",
        "\n",
        "vgg16.trainable = False\n",
        "print(\"\\n  Make all layers not trainable   \\n\\n\")\n",
        "\n",
        "for (i,layer) in enumerate(vgg16.layers):\n",
        "    print(str(i),'\\t', layer.__class__.__name__, '\\t',layer.trainable)"
      ],
      "metadata": {
        "id": "hEDNg9OJBAVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_2.add(vgg16)\n",
        "\n",
        "\n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(256, activation='relu'))\n",
        "model_2.add(Dropout(0.5))\n",
        "model_2.add(Dense(8, activation='softmax'))\n",
        "\n",
        "model_2.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "M4fPfmVFBqrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GD_RMSprop = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.7, epsilon=1e-07)\n",
        "\n",
        "model_2.compile(optimizer=GD_RMSprop,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_weights_freeze = model_2.fit(train_generator, steps_per_epoch=125, epochs=12, validation_data=(test_generator))"
      ],
      "metadata": {
        "id": "QF6VuBYdByUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history_after_training(history_weights_freeze)"
      ],
      "metadata": {
        "id": "uNXI0BA9B957"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_2.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "pDkA_O6PCEfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SGD_momentum = keras.optimizers.SGD(learning_rate=0.0001, momentum=0.9)\n",
        "\n",
        "\n",
        "model_2.compile(optimizer=SGD_momentum,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "FIX9cIU3CHSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_unfreeze = model_2.fit(train_generator, steps_per_epoch=125, epochs=20, validation_data=(test_generator))"
      ],
      "metadata": {
        "id": "kvIJYGkKCLJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history_after_training(history_unfreeze)"
      ],
      "metadata": {
        "id": "yYN4XaUZCPNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.save('model_2.h5')"
      ],
      "metadata": {
        "id": "G-vbmCTSCP_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25,7))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "\n",
        "plt.plot(history_unfreeze.history['loss'],':or',label = \"Train Data - Model 2 (VGG-like model)\")\n",
        "plt.plot(history_unfreeze.history['val_loss'],'-or',label = \"Test Data - Model 2 (VGG-like model)\")\n",
        "\n",
        "plt.plot(history_1_1.history['loss'],':ob',label = \"Train Data - Model 1\")\n",
        "plt.plot(history_1_1.history['val_loss'],'-ob',label = \"Test Data - Model 1\")\n",
        "\n",
        "plt.title('Loss',fontsize=14)\n",
        "plt.xlabel('Epochs',fontsize=14)\n",
        "plt.legend(loc = \"upper right\")\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "\n",
        "plt.plot(history_unfreeze.history['accuracy'],':or',label = \"Train Data - Model 2 (VGG-like model)\")\n",
        "plt.plot(history_unfreeze.history['val_accuracy'],'-or',label = \"Test Data - Model 2 (VGG-like model)\")\n",
        "\n",
        "plt.plot(history_1_1.history['accuracy'],':ob',label = \"Train Data - Model 1\")\n",
        "plt.plot(history_1_1.history['val_accuracy'],'-ob',label = \"Test Data - Model 1\")\n",
        "\n",
        "plt.ylim([0, 1])\n",
        "plt.title('Accuracy',fontsize=12)\n",
        "plt.xlabel('Epochs',fontsize=12)\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "icnZ4PStCW1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(history_unfreeze.history['val_accuracy'],'-or',label = \"Test Data - Model 2 (VGG-like model)\")\n",
        "\n",
        "plt.plot(history_1_1.history['val_accuracy'],'-ob',label = \"Test Data - Model 1\")\n",
        "\n",
        "\n",
        "\n",
        "plt.ylim([0, 1])\n",
        "plt.title('Accuracy',fontsize=12)\n",
        "plt.xlabel('Epochs',fontsize=12)\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "gE14iGXhCXWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = get_accuracy_and_loss(model_2, test_images, test_labels)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "id": "ek3W1lSYCZY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(model_2,tissue_types.values(),test_images,test_labels,'Model 2 using Transfer Learning')"
      ],
      "metadata": {
        "id": "SGcNi-wdChKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.save('model_2.h5')\n"
      ],
      "metadata": {
        "id": "G2iZ14AzCmH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_pred_2= model_2.predict(test_images).round(2)\n",
        "label_pred_2"
      ],
      "metadata": {
        "id": "iQVSoZr3IXTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,30))\n",
        "j=1\n",
        "for i in np.random.randint(0,1000,60):\n",
        "  plt.subplot(10,6,j);j+=1\n",
        "  plt.imshow(test_images[i],cmap='Greys')\n",
        "  plt.title('Actual = {} / {} \\nPredicted = {} / {}'.format(tissue_types[test_labels[i]],test_labels[i],tissue_types[np.argmax(label_pred_2[i])],np.argmax(label_pred_2[i])))\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "69AIUkovIr-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "label_pred_2=model_2.predict(test_images)\n",
        "label_pred_classes2=[np.argmax(element) for element in label_pred_2]\n",
        "print(\"Classification Report:\\n\",classification_report(test_labels,label_pred_classes2))\n"
      ],
      "metadata": {
        "id": "1hEZhFkSJOrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VY6yNrX_7qED"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "cell_execution_strategy": "setup",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}